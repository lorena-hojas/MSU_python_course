{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3faa754",
   "metadata": {},
   "source": [
    "MSU-USDA Python Workshop\n",
    "\n",
    "# Python for Data Science: Images and Batch Processing Things\n",
    "\n",
    "# Images\n",
    "\n",
    "In this notebook, we'll tackle images since they are so important to computer vision. This will also give us a chance to show how to do batch operations on lots of files.\n",
    "\n",
    "## I. Importing Libraries\n",
    "\n",
    "First, let's import the libraries needed for data wrangling, for visualization, and for working with images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d65bbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library that helps us deal with the file system and other operating system (os) stuff\n",
    "import os\n",
    "\n",
    "# Import our normal pandas and numpy used in wrangling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# These libraries allow us to work with images in matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# This is the pillow library for manipulating images\n",
    "from PIL import Image, ImageFilter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ec8f01",
   "metadata": {},
   "source": [
    "Matplotlib has an image library that we can use. It is documented here - https://matplotlib.org/stable/api/image_api.html. But we are going to use something more popular - Pillow.\n",
    "\n",
    "Pillow is documented here: https://pillow.readthedocs.io/en/stable/index.html\n",
    "\n",
    "## II. Loading an Image\n",
    "\n",
    "Let's load up an image from your hard drive with Pillow and then view the representation of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09118c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the file and then load it up as an image\n",
    "with Image.open('data/batch_in/Cheetah/cheetah-448901__480.jpg') as cheetah:\n",
    "    cheetah.load()\n",
    "\n",
    "# What Type is it?\n",
    "type(cheetah)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfac82c3",
   "metadata": {},
   "source": [
    "Ah, the image is a JPG; that's good - it matches the file extension (.jpg).\n",
    "\n",
    "What can we find out about this image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3640cf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Its format: \n",
    "print(cheetah.format)\n",
    "\n",
    "# Its size:\n",
    "print(cheetah.size)\n",
    "\n",
    "# Its color mode:\n",
    "print(cheetah.mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ece952",
   "metadata": {},
   "source": [
    "So, it's (width) 320 x (height) 480. That means it has this many pixels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d300fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cheetah.size[0] * cheetah.size[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c68d6c",
   "metadata": {},
   "source": [
    "And since the mode is \"RGB\" that means it is composed of RGB pixels (red, green, blue). If it were RGBA, it would have another value (\"A\") for level of transparency.\n",
    "\n",
    "## III. Viewing an Image\n",
    "\n",
    "Let's view it now in jupyter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5af947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter will show it right here\n",
    "display(cheetah)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8942d8c8",
   "metadata": {},
   "source": [
    "## IV. Cropping an Image\n",
    "\n",
    "Let's crop this image and just get the cheetah's face as an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40484b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The .crop() method crops out a box of the image.\n",
    "# The box is a 4-tuple defining the left, upper, right, and lower pixel coordinate - x,y / x,y\n",
    "# Documented here: https://pillow.readthedocs.io/en/stable/reference/Image.html#PIL.Image.Image.crop\n",
    "\n",
    "justTheFace = cheetah.crop((50, 100, 300, 350))\n",
    "display(justTheFace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3de168",
   "metadata": {},
   "source": [
    "Voila, just the head. The coordinate system assumed by the box we defined above is defined here https://pillow.readthedocs.io/en/stable/handbook/concepts.html#coordinate-system, but it is easy to remember. The upper lefthand corner of the image is at (0,0) and most programming languages use the convention of x,y (left-right, up-down)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4a71ae",
   "metadata": {},
   "source": [
    "### Exercise 1: Practicing Cropping\n",
    "\n",
    "Now, let's practice croppping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861ac993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. Crop out just the left eye and store in a variable\n",
    "\n",
    "# b. Print the dimensions of your cropped eye image using img attributes\n",
    "\n",
    "# c. Show your cropped eye image in this notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f132eb0",
   "metadata": {},
   "source": [
    "## V. Resizing an Image\n",
    "\n",
    "Sometimes images can be way too large to work with efficiently. It is common in computer vision work to reduce the size of images significantly.\n",
    "\n",
    "Let's resize our large Cheetah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413b88a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's give Pillow's resize method a tuple that defines the new width and height \n",
    "# of the image in pixels and let's get just 1/4 of the full size\n",
    "cheetahSmall = cheetah.resize((cheetah.width // 4, cheetah.height // 4))\n",
    "display(cheetahSmall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb242250",
   "metadata": {},
   "source": [
    "Notice that we used the \"floor division operator\" (//) in Python. Floor division rounds down to nearest integer. For example, the expression 11 // 4 evaluates to 2 in contrast to the 2.75 returned by float true division. The reason? Well, because resolution is in number of pixels and we can't have a fraction of a pixel.\n",
    "\n",
    "## VI. Saving an Image\n",
    "\n",
    "Now that we have a lower res image, let's save it and compare the file size. We'll save it as several different image formats. The Pillow library is smart enought to know the format just based on our file extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c47f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as PNG\n",
    "cheetahSmall.save(\"cheetahSmall.png\")\n",
    "\n",
    "# Save as JPG\n",
    "cheetahSmall.save(\"cheetahSmall.jpg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d7b22b",
   "metadata": {},
   "source": [
    "Now look at your directory and compare StarryNightSmall.png to StarryNightSmall.png. \n",
    "\n",
    "### Exercise 2: Comparing Image Sizes\n",
    "\n",
    "Just looking at your file system, answer a few questions about the images we just saved. No python is necessary for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1149b47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. How large (kilobytes) is the cheetahSmall.png?\n",
    "# \n",
    "\n",
    "# b. How large is cheetahSmall.jpg?\n",
    "# \n",
    "\n",
    "# c. Drag each image into a browser window; they should look pretty similar. do they?\n",
    "# \n",
    "\n",
    "# d. What advantage does the .jpg have? \n",
    "# \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd97367",
   "metadata": {},
   "source": [
    "One great thing about the .jpg format is that you can save it at different quality levels. Run this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d03897",
   "metadata": {},
   "outputs": [],
   "source": [
    "cheetahSmall.save(\"cheetahSmall100.jpg\", quality=100)\n",
    "cheetahSmall.save(\"cheetahSmall80.jpg\", quality=80)\n",
    "cheetahSmall.save(\"cheetahSmall50.jpg\", quality=50)\n",
    "cheetahSmall.save(\"cheetahSmall20.jpg\", quality=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a616780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# e. Which quality level takes up the most disk space?\n",
    "# 100\n",
    "\n",
    "# f. Compare the quality 100 to quality 20 - what's the difference?\n",
    "# quality 20 is very blurry / swishy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c1d926",
   "metadata": {},
   "source": [
    "## VII. Transposing Images\n",
    "\n",
    "Can I flip it? Yes you can."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398bf8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "cheetahFlipped = cheetah.transpose(Image.Transpose.FLIP_TOP_BOTTOM)\n",
    "\n",
    "display(cheetahFlipped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b97729",
   "metadata": {},
   "source": [
    "The Image.Transpose options are:\n",
    "        \n",
    "- Image.Tranpose.FLIP_LEFT_RIGHT: Flips the image left to right, resulting in a mirror image\n",
    "- Image.Tranpose.FLIP_TOP_BOTTOM: Flips the image top to bottom\n",
    "- Image.Tranpose.ROTATE_90: Rotates the image by 90 degrees counterclockwise\n",
    "- Image.Tranpose.ROTATE_180: Rotates the image by 180 degrees\n",
    "- Image.Tranpose.ROTATE_270: Rotates the image by 270 degrees counterclockwise, which is the same as 90 degrees clockwise\n",
    "- Image.Tranpose.TRANSPOSE: Transposes the rows and columns using the top-left pixel as the origin, with the top-left pixel being the same in the transposed image as in the original image\n",
    "- Image.Tranpose.TRANSVERSE: Transposes the rows and columns using the bottom-left pixel as the origin, with the bottom-left pixel being the one that remains fixed between the original and modified versions\n",
    "\n",
    "For example, we can rotate it 90 degrees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f47694",
   "metadata": {},
   "outputs": [],
   "source": [
    "cheetahRotated = cheetah.transpose(Image.Transpose.ROTATE_90)\n",
    "\n",
    "display(cheetahRotated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5154854d",
   "metadata": {},
   "source": [
    "You can also arbitrarily rotate it by any angle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6b2950",
   "metadata": {},
   "outputs": [],
   "source": [
    "cheetahRotatedNegative17 = cheetah.rotate(-17)\n",
    "\n",
    "display(cheetahRotatedNegative17)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e803502",
   "metadata": {},
   "source": [
    "You can see that we ended up cutting off the corners. We need to give pillow the permission to make the image larger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba5e2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cheetahRotatedNegative17 = cheetah.rotate(-17, expand=True)\n",
    "display(cheetahRotatedNegative17)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d01cc4",
   "metadata": {},
   "source": [
    "## VIII. Changing the Color Scale\n",
    "\n",
    "Let's make our image into a greyscale image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da13b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "grayCheetah = cheetah.convert(\"L\")\n",
    "display(grayCheetah)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914f980f",
   "metadata": {},
   "source": [
    "Converting, in this case, was from RGB to L.\n",
    "\n",
    "## IX. Smoothing / Sharpening / Blurring\n",
    "\n",
    "You can also transform images just like you could in Photoshop.\n",
    "\n",
    "The .Filter() supports:\n",
    "\n",
    "- BLUR\n",
    "- CONTOUR\n",
    "- DETAIL\n",
    "- EDGE_ENHANCE\n",
    "- EDGE_ENHANCE_MORE\n",
    "- EMBOSS\n",
    "- FIND_EDGES\n",
    "- SHARPEN\n",
    "- SMOOTH\n",
    "- SMOOTH_MORE\n",
    "\n",
    "Let's sharpen the small image we made earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161bfa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show what we started with\n",
    "display(cheetah)\n",
    "\n",
    "# sharpen it\n",
    "sharperCheetah = cheetah.filter(ImageFilter.SHARPEN)\n",
    "\n",
    "# Show the after\n",
    "display(sharperCheetah)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7189077f",
   "metadata": {},
   "source": [
    "Most of the time, when you reduce the size of an image you'll need to do some sharpening. The resize also supports various ways to 'interpolate' an image - a strategy for how to handle going from, in our case, 4 pixels to 1.\n",
    "\n",
    "Enhancing edges can be useful in preparing images for computer vision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f8612b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find edges and show\n",
    "cheetahEdges = cheetah.filter(ImageFilter.EDGE_ENHANCE)\n",
    "display(cheetahEdges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a71caf2",
   "metadata": {},
   "source": [
    "## X. Batch Processing of Images\n",
    "\n",
    "Often, in a machine learning project, you'll need to batch process files, especially images.\n",
    "\n",
    "In the data/batch_in/Cheetah directory are several images of cheetahs. Let's process them in batch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2667478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# where to read them from\n",
    "inputImagePath = \"data/batch_in/Cheetah\"\n",
    "\n",
    "# where to save them\n",
    "# be sure you create this output directory\n",
    "outputImagePath = \"data/batch_out/Cheetah\"\n",
    "\n",
    "# let's scale them down by 75% (divide by four)\n",
    "resizeAmount = 4\n",
    "\n",
    "# open up the source directory\n",
    "with os.scandir(inputImagePath) as fileList:\n",
    "    # loop through all the files in the filelist\n",
    "    for entry in fileList:\n",
    "        # if the file is a jpg, then..\n",
    "        if (entry.name.endswith(\".jpg\") or entry.name.endswith(\".jpeg\")) and entry.is_file():\n",
    "            # open it\n",
    "            with Image.open(entry.path) as bigImage:\n",
    "                # resize it using the .thumbnail method\n",
    "                bigImage.thumbnail((bigImage.width // resizeAmount,bigImage.height // resizeAmount))\n",
    "                # create a new name out of the old name\n",
    "                newName = outputImagePath + \"/\" + entry.name\n",
    "                # save the resized image as a JPEG at quality 100\n",
    "                # notice we used a slightly different method for saving here than above\n",
    "                bigImage.save(newName, \"JPEG\", quality=100)\n",
    "                # give some feedback to ourselves so we can see what was processed\n",
    "                print(f\"processing file {entry.name} ..done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca42280",
   "metadata": {},
   "source": [
    "Nice, right? Your data/batch_out/Cheetah directory should be full of images now.\n",
    "\n",
    "Doesn't it feel powerful to do so many things automatically?\n",
    "\n",
    "### Exercise 3: Putting it all Together\n",
    "\n",
    "In this exercise you will batch process some Jaguar images to get them ready for machine learning. You'll be able to practice several image manipulation methods and the use of functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f118f719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code to batch process these and save in data/batch_out/Jaguar\n",
    "\n",
    "# 1. Write a function that takes a Pillow image and\n",
    "#    a. flips the original image\n",
    "#    b. resize the new combined image by half\n",
    "#    c. sharpens the resized image\n",
    "\n",
    "\n",
    "\n",
    "# 2. Loop through all the images in the data/batch_in/Jaguar directory and\n",
    "#    a. call your function to get a transformed version\n",
    "#    b. save the transformed image to data/batch_out/Jaguar\n",
    "#       Use quality level 80 for the jpgs.\n",
    "#    c. provide feedback to the user as each file is processing.\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ca74d2-bbb0-45f9-96b1-ed66a2d31f5f",
   "metadata": {},
   "source": [
    "## X. Further Thoughts\n",
    "\n",
    "Sometimes, for machine vision projects, the data scientist will make many versions of the same image by cropping it randomly, rotating randomly, desaturating it, changing colors, etc. This way you end up with more training data to build a model that generalizes against many different ways in which an object appears in an image."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyworkshop] *",
   "language": "python",
   "name": "conda-env-pyworkshop-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
